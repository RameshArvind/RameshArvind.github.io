<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Ramesh&#39;s Blog</title>
    <link>http://RameshArvind.github.io/posts/</link>
    <description>Recent content in Posts on Ramesh&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 03 Feb 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="http://RameshArvind.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>What do I consume on the internet</title>
      <link>http://RameshArvind.github.io/posts/personal/what-i-consume-in-the-internet/</link>
      <pubDate>Mon, 03 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>http://RameshArvind.github.io/posts/personal/what-i-consume-in-the-internet/</guid>
      <description>There&#39;s so much content out there between
 YouTube Reddit Twitter Hacker News Twitch  I&#39;m at the point where I can&#39;t not have one of those tabs open regardless of what I&#39;m working.
General Content that interests me  Reinforcement Learning Unusual applications of machine learning Links explaining social phenomena Content creators that I follow  Twitter I usually start the day checking out twitter. I follow mostly people in the machine learning scene.</description>
    </item>
    
    <item>
      <title>Year in Review 2019</title>
      <link>http://RameshArvind.github.io/posts/personal/year-in-review-2019/</link>
      <pubDate>Tue, 31 Dec 2019 22:41:08 -0500</pubDate>
      
      <guid>http://RameshArvind.github.io/posts/personal/year-in-review-2019/</guid>
      <description>Well here we are. Its 2020, another year/decade. I didn&#39;t do a review last year but hopefully starting this year I&#39;ll try to be more conscious about it.
Things that happened  January  ML fellowship at fellowship.ai 2nd semester in OMSCS - Reinforcement Learning and Machine Learning for Trading   February / March  Externship at fellowship.ai Opportunity to shift to MSCS on campus   April / May / June / July  Taking time off from studying   August  Moved to Atlanta 3rd semester at Georgia Tech - Machine Learning / Deep Learning for Videos / Computer Vision   September / October  Summer Internship Hunt Interviewed at Amazon Robotics / Neosis / Worthix / Credit Karma   November  Internship offer from Worthix   December  Wrapping up semester Studying up on AlphaGO - MCTS / UCT    Reflections for 2019 I started a master&#39;s program to just get my foot into machine learning jobs, but honestly those 60 odd questions I solved on leetcode gave me the confidence I was lacking in my earlier job hunt than the masters program itself.</description>
    </item>
    
    <item>
      <title>Why I Got Into Computer Science</title>
      <link>http://RameshArvind.github.io/posts/personal/why-i-got-into-cs/</link>
      <pubDate>Wed, 02 Jan 2019 10:25:40 +0530</pubDate>
      
      <guid>http://RameshArvind.github.io/posts/personal/why-i-got-into-cs/</guid>
      <description>This dates back to when I was in high school around start of my 10th grade. I got access to internet for the first time in my life 1.
Up until this point, my only interactions with a computer was purely as a device for gaming. I used to spend a disproportionate of time playing games 2.
I made an account on facebook and played the games on it cause it was all the rage at the time.</description>
    </item>
    
    <item>
      <title>Georgia Tech&#39;s OMSCS Program</title>
      <link>http://RameshArvind.github.io/posts/personal/what-is-omscs/</link>
      <pubDate>Wed, 02 Jan 2019 07:31:49 +0530</pubDate>
      
      <guid>http://RameshArvind.github.io/posts/personal/what-is-omscs/</guid>
      <description>OMSCS is Georgia Tech&#39;s Online Master&#39;s Program in Computer Science. It is run fully online, generally taken up by working professionals.
I enrolled into the program in Fall Semester (September - December) of 2018 thus completing one semester at the time of writing.
Before I considered OMSCS I originally intended to apply to on-campus programs in the US, but I ended up skipping out multiple times
 First when my peers applied right out of their undergraduate program When my co-workers applied first year into their career and when they applied second year into their career  Each time I kept thinking &amp;ldquo;I&#39;m not going to procrastinate this year and apply&amp;rdquo;.</description>
    </item>
    
    <item>
      <title>Multi-Armed Bandits</title>
      <link>http://RameshArvind.github.io/posts/reinforcement-learning/multi-armed-bandits/</link>
      <pubDate>Sat, 22 Dec 2018 05:31:27 +0530</pubDate>
      
      <guid>http://RameshArvind.github.io/posts/reinforcement-learning/multi-armed-bandits/</guid>
      <description>Preface All of the content here is to be a summary/notes for the multi-armed bandits chapter in the 2nd edition of the book Reinforcement Learning: An Introduction by Sutton and Barto.
What is the MAB problem? Consider k different slot machines each with different payouts and probabilities of winning. Our goal is to maximize winnings over it without any prior knowledge of the machines.
Think about being in a casino with no one around except you.</description>
    </item>
    
    <item>
      <title>First Post</title>
      <link>http://RameshArvind.github.io/posts/personal/first-post/</link>
      <pubDate>Thu, 20 Dec 2018 04:41:02 +0530</pubDate>
      
      <guid>http://RameshArvind.github.io/posts/personal/first-post/</guid>
      <description>Why even blog? So then, this is probably going to be a pretty boring intro to what I&#39;m trying to get at by blogging.
I spend a lot time on the internet, it&#39;s actually more surprising when I don&#39;t find myself on it. I&#39;m easily distracted when I&#39;m trying to be productive and have a hard time trying to focus. There are specific things I&#39;d like to achieve by blogging</description>
    </item>
    
    <item>
      <title></title>
      <link>http://RameshArvind.github.io/posts/reinforcement-learning/reinforcement-learning-for-caching/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://RameshArvind.github.io/posts/reinforcement-learning/reinforcement-learning-for-caching/</guid>
      <description>Reinforcement Learning for Caching Databases are ubiquitous in the world of internet companies. Almost every company today has a system of records for their users, content, transactions and a variety of other forms of data. Processing large amounts of data efficiently has been a key component of database research for many decades by optimizing different database components.
One such component is the cache. It is used to reduce the amount of disk reads / writes to optimize latency.</description>
    </item>
    
  </channel>
</rss>