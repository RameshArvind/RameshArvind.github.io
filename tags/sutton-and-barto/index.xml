<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Sutton and Barto on Ramesh&#39;s Blog</title>
    <link>http://RameshArvind.github.io/tags/sutton-and-barto/</link>
    <description>Recent content in Sutton and Barto on Ramesh&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 22 Dec 2018 05:31:27 +0530</lastBuildDate>
    
	<atom:link href="http://RameshArvind.github.io/tags/sutton-and-barto/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Multi-Armed Bandits</title>
      <link>http://RameshArvind.github.io/posts/reinforcement-learning/multi-armed-bandits/</link>
      <pubDate>Sat, 22 Dec 2018 05:31:27 +0530</pubDate>
      
      <guid>http://RameshArvind.github.io/posts/reinforcement-learning/multi-armed-bandits/</guid>
      <description>Preface All of the content here is to be a summary/notes for the multi-armed bandits chapter in the 2nd edition of the book Reinforcement Learning: An Introduction by Sutton and Barto.
What is the MAB problem? Consider k different slot machines each with different payouts and probabilities of winning. Our goal is to maximize winnings over it without any prior knowledge of the machines.
Think about being in a casino with no one around except you.</description>
    </item>
    
  </channel>
</rss>